# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/Cluster full set 1046 images.ipynb (unless otherwise specified).

__all__ = ['generate_features', 'show_examples', 'show_cluster_examples', 'save_cluster_images',
           'save_cluster_examples']

# Cell

# export

import fastai
from fastai.vision.all import *


# Cell

import torch
import torchvision.models as models
import tqdm

from torchvision import datasets, transforms
import matplotlib.pyplot as plt



# Cell

def generate_features(dataloader, nnmodel, norm= True, max_batch= -1):
    '''
    generate embeddings for images specified in the dataloader using the neural net (nnmodel)

    input:
        dataloader:
        nnmodel: modified neural net model that uses AdaptiveAvgPool2d to combine the embeddings
        norm: if true, normalize the input images according to Resnet specs
        max_batch: used in dev mode to test the first max_batch batches

    returns:
        embeddings as a matrix
    '''
    print("Total: {} batches".format(len(dataloader)))
    if max_batch>0:
        print("[DEV] Max_batch= {}".format(max_batch))

    preproc= transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

    all_features= None
    batch_id= 0

    with torch.no_grad():
        for img, lab in (iter(dataloader)):
            # normalize images per Resnet specs
            if norm:
                features= nnmodel(preproc(img))
            else:
                features= nnmodel(img)

            if batch_id % 100==0:
                print("doing batch #{} -> size= {}".format(batch_id, img.shape[0]))
            if all_features is None:
                all_features= features
            else:
                all_features= torch.cat([all_features, features])
            batch_id+= 1

            if batch_id== max_batch:
                break
    return all_features

# Cell

def show_examples(images, nx= 5, ny= 5, size= (12,12), titles= None, gap= False):
    '''
    show an array of images on a grid

    images: ndarray (num_images x channels x H x W)
    nx: number of columns
    ny: number of rows
    titles: if provided as a list, show the titles above images. otherwise "File N" will be used as titles
    gap: show space between images
    '''
    # nx= 5
    # ny= 5

    f, axs= plt.subplots(nx,ny, figsize= size)
    total_n= images.shape[0]
    cnt= 0
    for i in range(nx):
        for j in range(ny):
            axs[i,j].set_xticks([])
            axs[i,j].set_yticks([])
            if cnt >= total_n:
                axs[i,j].axis('off')
                continue
            axs[i,j].imshow(images[cnt].numpy().transpose((1,2,0)))

            if titles is not None and len(titles)> cnt:
                axs[i,j].set_title(titles[cnt])
            else:
                axs[i,j].set_title("File {}".format(cnt))

            cnt+=1
    if gap is False:
        f.subplots_adjust(wspace=0, hspace=0)
    else:
        f.tight_layout()


def show_cluster_examples(cid, dataset, kmeans, nx= 5, ny= 5, rnd= True, titles= False, **kwargs):
    '''
    show a grid of cluster examples

    cid: cluster ID
    dataset:
    kmeans:
    nx, ny: number of images on each axis
    rnd: randomly select from cluster images; otherwise take the first few images
    titles: show file index as title

    '''
    n= nx* ny
    all_idx = np.array([*range(len(dataset))])

    to_do_idx= all_idx[kmeans.labels_== cid]
    if rnd:
        to_do_idx= np.random.choice(to_do_idx, size= n)
    else:
        to_do_idx= to_do_idx[:n]
    if titles is True:
        to_do_title= ["File {}".format(i) for i in to_do_idx]
    else:
        to_do_title= [''] * n
    example_imgs= torch.stack([dataset[i][0] for i in to_do_idx ])
    print("{} images found for cluster {}".format(example_imgs.shape[0], cid))
    show_examples(example_imgs, nx, ny, titles= to_do_title, **kwargs)

# Cell

from matplotlib.backends.backend_pdf import PdfPages

def save_cluster_images(dataset, km, outfile):
    '''
    dataset:
    km: kmeans model
    outfile: pdf file
    '''
    with PdfPages(outfile) as pdf:
        for i in range(km.n_clusters):
            show_cluster_examples(i, dataset, km, 10, 10, size= (15,15), gap= False, titles= False)
            plt.suptitle("Cluster {}".format(i))
            pdf.savefig()
            plt.close()

# Cell

import os
from tqdm import tqdm

def save_cluster_examples(images, kmeans, n= 25, out= 'output/export/clusters', rnd= True, titles= False, run= False, **kwargs):
    '''
    export cluster examples as PNG files

    cid: cluster ID
    dataset:
    kmeans:
    n: number of samples per cluster
    rnd: randomly select from cluster images; otherwise take the first few images
    titles: show file index as title
    run: execute the image exporting commands

    '''

    if not os.path.exists(out):
        os.mkdir(out)
        print("creating output directory: {}".format(out))

    print("{} clusters found".format(kmeans.n_clusters))

    all_idx = np.array([*range(len(images))])

    all_cmd= []
    for cid in tqdm(range(kmeans.n_clusters)):
        print("exporting cluster {}".format(cid))
        to_do_idx= all_idx[kmeans.labels_== cid]
        if rnd:
            np.random.seed(0)
            to_do_idx= np.random.choice(to_do_idx, size= n)
        else:
            to_do_idx= to_do_idx[:n]

        example_imgs= [images[i][0] for i in to_do_idx ]
        print("{} images found for cluster {}".format(len(example_imgs), cid))

        # cmd= ["cp {} {}".format() for i in exampl
        cmd= ["cp {} {}/example_cluster{}_image{}.png".format(j, out, cid, i) for i, j in enumerate(example_imgs)]
        all_cmd.append(cmd)

    print("Total: {} images".format(len(all_cmd)))

    if run:
        for i in tqdm(list(np.concatenate(all_cmd))):
            os.system(i)
    return all_cmd